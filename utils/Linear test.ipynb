{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a242df-8f13-4d05-ab54-0c1850b6da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ca63b8-80d0-4143-8d43-d5fe2e6c1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/df_train.csv')\n",
    "\n",
    "y_train = train[['load_shortfall_3h']]\n",
    "X_train = train[['Madrid_wind_speed','Bilbao_rain_1h','Valencia_wind_speed','Madrid_temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc79f52-c50e-4d0e-b7e9-6de0dad355fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_regression = LinearRegression(normalize=True)\n",
    "print (\"Training Model...\")\n",
    "lm_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54ae57c-1d81-4de5-8180-809d0b6db39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Saving model to: ../assets/trained-models/load_shortfall_simple_lm_regression.pkl\n"
     ]
    }
   ],
   "source": [
    "save_path = '../assets/trained-models/load_shortfall_simple_lm_regression.pkl'\n",
    "print (f\"Training completed. Saving model to: {save_path}\")\n",
    "pickle.dump(lm_regression, open(save_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4749f-cd60-410e-84ca-36ca89017050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
